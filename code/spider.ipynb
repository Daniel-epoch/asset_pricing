{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ticker = yf.Ticker('APPL')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "Timeout",
     "evalue": "Failed to perform, curl: (28) Connection timed out after 30012 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCurlError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\curl_cffi\\requests\\session.py:652\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, json, headers, cookies, files, auth, timeout, allow_redirects, max_redirects, proxies, proxy, proxy_auth, verify, referer, accept_encoding, content_callback, impersonate, ja3, akamai, extra_fp, default_headers, default_encoding, quote, http_version, interface, cert, stream, max_recv_speed, multipart, discard_cookies)\u001B[0m\n\u001B[0;32m    651\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 652\u001B[0m         \u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CurlError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\curl_cffi\\curl.py:422\u001B[0m, in \u001B[0;36mCurl.perform\u001B[1;34m(self, clear_headers, clear_resolve)\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 422\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mperform\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    424\u001B[0m     \u001B[38;5;66;03m# cleaning\u001B[39;00m\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\curl_cffi\\curl.py:199\u001B[0m, in \u001B[0;36mCurl._check_error\u001B[1;34m(self, errcode, *args)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 199\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\n",
      "\u001B[1;31mCurlError\u001B[0m: Failed to perform, curl: (28) Connection timed out after 30012 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTimeout\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 获取市场新闻（通过任意大型公司的代码）\u001B[39;00m\n\u001B[0;32m      5\u001B[0m ticker \u001B[38;5;241m=\u001B[39m yf\u001B[38;5;241m.\u001B[39mTicker(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^GSPC\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# 示例：标普500指数\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m news \u001B[38;5;241m=\u001B[39m \u001B[43mticker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnews\u001B[49m\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\yfinance\\ticker.py:316\u001B[0m, in \u001B[0;36mTicker.news\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mnews\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_news\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\yfinance\\base.py:694\u001B[0m, in \u001B[0;36mTickerBase.get_news\u001B[1;34m(self, count, tab, proxy)\u001B[0m\n\u001B[0;32m    686\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_ROOT_URL_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/xhr/ncp?queryRef=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_ref\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m&serviceKey=ncp_fin\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    687\u001B[0m payload \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    688\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserviceConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    689\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msnippetCount\u001B[39m\u001B[38;5;124m\"\u001B[39m: count,\n\u001B[0;32m    690\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mticker]\n\u001B[0;32m    691\u001B[0m     }\n\u001B[0;32m    692\u001B[0m }\n\u001B[1;32m--> 694\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWill be right back\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mtext:\n\u001B[0;32m    696\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*** YAHOO! FINANCE IS CURRENTLY DOWN! ***\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    697\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOur engineers are working quickly to resolve \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    698\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe issue. Thank you for your patience.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\yfinance\\utils.py:92\u001B[0m, in \u001B[0;36mlog_indent_decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEntering \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m IndentationContext():\n\u001B[1;32m---> 92\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     94\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExiting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\yfinance\\data.py:374\u001B[0m, in \u001B[0;36mYfData.post\u001B[1;34m(self, url, body, params, timeout)\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;129m@utils\u001B[39m\u001B[38;5;241m.\u001B[39mlog_indent_decorator\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\u001B[38;5;28mself\u001B[39m, url, body, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m):\n\u001B[1;32m--> 374\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_method\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\yfinance\\utils.py:92\u001B[0m, in \u001B[0;36mlog_indent_decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEntering \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m IndentationContext():\n\u001B[1;32m---> 92\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     94\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExiting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\yfinance\\data.py:406\u001B[0m, in \u001B[0;36mYfData._make_request\u001B[1;34m(self, url, request_method, body, params, timeout)\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m body:\n\u001B[0;32m    404\u001B[0m     request_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m body\n\u001B[1;32m--> 406\u001B[0m response \u001B[38;5;241m=\u001B[39m request_method(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrequest_args)\n\u001B[0;32m    407\u001B[0m utils\u001B[38;5;241m.\u001B[39mget_yf_logger()\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresponse code=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m400\u001B[39m:\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;66;03m# Retry with other cookie strategy\u001B[39;00m\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\curl_cffi\\requests\\session.py:678\u001B[0m, in \u001B[0;36mSession.post\u001B[1;34m(self, url, **kwargs)\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Unpack[RequestParams]):\n\u001B[1;32m--> 678\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\app\\anaconda\\envs\\daniel\\lib\\site-packages\\curl_cffi\\requests\\session.py:659\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, json, headers, cookies, files, auth, timeout, allow_redirects, max_redirects, proxies, proxy, proxy_auth, verify, referer, accept_encoding, content_callback, impersonate, ja3, akamai, extra_fp, default_headers, default_encoding, quote, http_version, interface, cert, stream, max_recv_speed, multipart, discard_cookies)\u001B[0m\n\u001B[0;32m    657\u001B[0m     rsp\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m req\n\u001B[0;32m    658\u001B[0m     error \u001B[38;5;241m=\u001B[39m code2error(e\u001B[38;5;241m.\u001B[39mcode, \u001B[38;5;28mstr\u001B[39m(e))\n\u001B[1;32m--> 659\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error(\u001B[38;5;28mstr\u001B[39m(e), e\u001B[38;5;241m.\u001B[39mcode, rsp) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    660\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    661\u001B[0m     rsp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_response(\n\u001B[0;32m    662\u001B[0m         c, buffer, header_buffer, default_encoding, discard_cookies\n\u001B[0;32m    663\u001B[0m     )\n",
      "\u001B[1;31mTimeout\u001B[0m: Failed to perform, curl: (28) Connection timed out after 30012 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details."
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import json\n",
    "\n",
    "# 获取市场新闻（通过任意大型公司的代码）\n",
    "ticker = yf.Ticker(\"^GSPC\")  # 示例：标普500指数\n",
    "news = ticker.news\n",
    "# news 已是一个包含标题、链接、发布时间等信息的列表\n",
    "# 可进一步访问链接获取全文（仍需处理详情页）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mselenium\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m webdriver\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mselenium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwebdriver\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mby\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m By\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mselenium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwebdriver\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msupport\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mui\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m WebDriverWait\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "class YahooFinanceNewsScraper:\n",
    "    def __init__(self):\n",
    "        # 初始化Chrome浏览器驱动，请确保已下载对应版本的chromedriver\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # 可选：添加以下参数以在后台运行（无头模式）\n",
    "        # options.add_argument('--headless')\n",
    "        # 添加用户代理等参数模拟真实浏览器\n",
    "        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        self.news_data = []  # 用于存储最终结果的列表\n",
    "\n",
    "    def fetch_news_list(self, url='https://finance.yahoo.com/'):\n",
    "        \"\"\"获取新闻列表页，并提取新闻链接和摘要信息\"\"\"\n",
    "        print(\"正在访问Yahoo Finance首页...\")\n",
    "        self.driver.get(url)\n",
    "        time.sleep(random.uniform(3, 5))  # 等待页面加载，可调整时间或使用显式等待\n",
    "\n",
    "        # 解析页面\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "        # **关键：此处需要根据Yahoo Finance的实际HTML结构调整选择器**\n",
    "        # 示例选择器（很可能需要修改）：\n",
    "        # 通常新闻条目可能在特定的容器内，如具有特定类的< li >, < div >或< article >标签\n",
    "        news_items = soup.select('h3 a')  # 这只是一个非常通用的示例，需要替换\n",
    "\n",
    "        news_list = []\n",
    "        for item in news_items:\n",
    "            link = item.get('href')\n",
    "            title = item.get_text(strip=True)\n",
    "            if link and title:\n",
    "                # 补全相对链接\n",
    "                if link.startswith('/'):\n",
    "                    link = f'https://finance.yahoo.com{link}'\n",
    "                news_list.append({'title': title, 'link': link})\n",
    "                print(f\"找到新闻: {title}\")\n",
    "\n",
    "        print(f\"共找到 {len(news_list)} 条新闻链接。\")\n",
    "        return news_list[:10]  # 限制爬取数量以避免请求过多\n",
    "\n",
    "    def fetch_news_detail(self, news_item):\n",
    "        \"\"\"访问单条新闻详情页，提取全文和发布时间\"\"\"\n",
    "        print(f\"正在爬取详情: {news_item['title'][:50]}...\")\n",
    "        try:\n",
    "            self.driver.get(news_item['link'])\n",
    "            time.sleep(random.uniform(2, 4))  # 等待详情页加载\n",
    "\n",
    "            detail_soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "            # **关键：提取新闻正文和发布时间**\n",
    "            # 1. 提取正文：通常位于<article>、<div class=\"article-body\">等标签内\n",
    "            # 需要手动审查详情页HTML结构来确定正确的选择器\n",
    "            content_div = detail_soup.find('div', class_='caas-body')  # 示例选择器，需要验证\n",
    "            full_text = content_div.get_text(separator='\\n', strip=True) if content_div else \"正文未找到\"\n",
    "\n",
    "            # 2. 提取发布时间：可能在<time>、<div class=\"date\">等标签内\n",
    "            time_tag = detail_soup.find('time')  # 示例选择器，需要验证\n",
    "            publish_time = time_tag.get('datetime') if time_tag else \"时间未找到\"\n",
    "\n",
    "            news_item['full_text'] = full_text\n",
    "            news_item['publish_time'] = publish_time\n",
    "            news_item['crawled_time'] = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"爬取详情页时出错: {e}\")\n",
    "            news_item['full_text'] = \"爬取失败\"\n",
    "            news_item['publish_time'] = \"爬取失败\"\n",
    "\n",
    "        return news_item\n",
    "\n",
    "    def scrape_to_json(self, output_filename='yahoo_finance_news.json'):\n",
    "        \"\"\"主函数：执行爬取并保存为JSON\"\"\"\n",
    "        news_list = self.fetch_news_list()\n",
    "\n",
    "        for news in news_list:\n",
    "            detailed_news = self.fetch_news_detail(news)\n",
    "            self.news_data.append(detailed_news)\n",
    "            # 随机延迟，降低请求频率\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "\n",
    "        # 保存为JSON文件\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.news_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"爬取完成！数据已保存至 {output_filename}\")\n",
    "        return self.news_data\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"关闭浏览器\"\"\"\n",
    "        self.driver.quit()\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = YahooFinanceNewsScraper()\n",
    "    try:\n",
    "        data = scraper.scrape_to_json()\n",
    "        # 打印前两条数据作为预览\n",
    "        for i, news in enumerate(data[:2]):\n",
    "            print(f\"\\n--- 新闻 {i+1} 预览 ---\")\n",
    "            print(f\"标题: {news['title']}\")\n",
    "            print(f\"时间: {news['publish_time']}\")\n",
    "            print(f\"正文前100字符: {news['full_text'][:100]}...\")\n",
    "    finally:\n",
    "        scraper.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42e6917b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_yahoo_news(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"请求失败: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    news_items = []\n",
    "    \n",
    "    # 关键：这里的选择器需要根据实际网页结构调整\n",
    "    # 示例：假设新闻标题在<h3>标签内，链接在<a>标签的'href'属性中\n",
    "    for item in soup.select('h3 a'):  # 这只是一个示例，很可能不正确\n",
    "        title = item.get_text(strip=True)\n",
    "        link = item.get('href')\n",
    "        if title and link:\n",
    "            # 补全可能为相对链接的URL\n",
    "            if link.startswith('/'):\n",
    "                link = f'https://finance.yahoo.com{link}'\n",
    "            news_items.append({'title': title, 'link': link})\n",
    "    \n",
    "    return news_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d45bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "news_list = scrape_yahoo_news('https://finance.yahoo.com/topic/stock-market-news/')\n",
    "for news in news_list[:5]:\n",
    "    print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79814c73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}